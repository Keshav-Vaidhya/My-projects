{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f380ec5",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9dc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea7aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f54e9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f78246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f021565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee891f88",
   "metadata": {},
   "source": [
    "## Fetching the transcipts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9288a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_captions(video_url):\n",
    "    vdo_id = video_url.split('=')[1]\n",
    "    return YouTubeTranscriptApi.list_transcripts(vdo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e691c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_or_auto(transcript_list):\n",
    "    try:\n",
    "        return transcript_list.find_manually_created_transcript(['en-US', 'en'])\n",
    "    except:\n",
    "        return transcript_list.find_generated_transcript(['en', 'en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9fd3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetching(ts):\n",
    "    transcripts = ts.fetch()\n",
    "    text = \"\"\n",
    "    for txt in transcripts:\n",
    "        text += txt['text']+\" \"\n",
    "    text = text.replace(\"\\ \",\" \")\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5755f45",
   "metadata": {},
   "source": [
    "## NLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41204e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dd952",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4078ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(doc):\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c59b24",
   "metadata": {},
   "source": [
    "## Recording Word Frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62422849",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations =''\n",
    "def word_freq_table(doc,tokens):\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    punctuations = punctuation + '\\n'\n",
    "    word_frequencies = {}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords:\n",
    "            if word.text.lower() not in punctuations:\n",
    "                if word.text.lower() not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text.lower()] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text.lower()] += 1\n",
    "    return word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12ae8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(word_frequencies):\n",
    "    max_freq = max(word_frequencies.values())\n",
    "    for w in word_frequencies.keys():\n",
    "        word_frequencies[w] = word_frequencies[w]/max_freq\n",
    "    return word_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d446ea",
   "metadata": {},
   "source": [
    "## Sentence Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d58dd2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_scoring(doc,word_frequencies):\n",
    "    sentence_tokens = [s for s in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "    return sentence_tokens,sentence_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c4bf8",
   "metadata": {},
   "source": [
    "## Summarization and Length Regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a1c1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(sentence_tokens,sentence_scores,percent):\n",
    "    p = int(percent)/100.0\n",
    "    req_len = int(len(sentence_tokens)*p)\n",
    "    summary = nlargest(req_len, sentence_scores, key = sentence_scores.get)\n",
    "    final = [word.text for word in summary]\n",
    "    final_summary = ' '.join(final)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8da97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer(video_url,percent):\n",
    "    try:\n",
    "        transcript_list = get_captions(video_url)\n",
    "    except:\n",
    "        messagebox.showerror(\"No transcripts found\", \"Either no transcripts available or invalid link\")\n",
    "    else:   \n",
    "        ts = manual_or_auto(transcript_list)\n",
    "        text = fetching(ts)\n",
    "        doc = model(text)\n",
    "        tokens = tokenization(doc)\n",
    "        word_frequencies = word_freq_table(doc,tokens)\n",
    "        word_freq = normalization(word_frequencies)\n",
    "        sentence_tokens,sentence_scores = sentence_scoring(doc,word_freq)\n",
    "    try:\n",
    "        summary = get_summary(sentence_tokens,sentence_scores,percent)\n",
    "    except:\n",
    "        messagebox.showwarning(\"% Length invalid\",\"The summary length % is either empty or invalid\")\n",
    "    else:\n",
    "        tday = date.today()\n",
    "        curr = time.strftime(\"%H%M%S\", time.localtime())\n",
    "        with open(\"Documents/Summary\" + str(tday) + curr + \".txt\",\"w\") as file:\n",
    "            file.write(summary)\n",
    "        messagebox.showinfo(\"Summarization Complete\",\"Please check your Documents folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f27a5",
   "metadata": {},
   "source": [
    "## GUI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf47cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.geometry(\"500x280\")\n",
    "root.title(\"Video Transcript Summarizer\")\n",
    "root.configure(background='lightblue')\n",
    "icon = PhotoImage(file = 'S-icon.png')\n",
    "root.iconphoto(False, icon)\n",
    "\n",
    "titlelbl = Label(root,text=\"Video Transcript Summarizer\",font=(\"Times New Roman\",20,\"italic\"),background='lightblue')\n",
    "titlelbl.place(x=75,y=20)\n",
    "\n",
    "link = Entry(root, width=55,borderwidth=2)\n",
    "link.place(x=140,y=100)\n",
    "\n",
    "urllbl = Label(root,text=\"Video URL:\",font=(\"Times New Roman\",14,\"italic\"),background='lightblue')\n",
    "urllbl.place(x=20,y=100)\n",
    "\n",
    "percentlbl = Label(root,text=\"% Length:\",font=(\"Times New Roman\",14,\"italic\"),background='lightblue')\n",
    "percentlbl.place(x=35,y=150)\n",
    "\n",
    "percent = Entry(root, width=10,borderwidth=2)\n",
    "percent.place(x=140,y=150)\n",
    "\n",
    "suggestlbl = Label(root,text=\"(Suggested: 30)\",font=(\"Times New Roman\",12,\"italic\"),background='lightblue')\n",
    "suggestlbl.place(x=220,y=150)\n",
    "\n",
    "plbl = Label(root,text=\"(Summary length % compared to original text between 10 to 100)\",font=(\"Times New Roman\",12,\"italic\")\n",
    "             ,background='lightblue')\n",
    "plbl.place(x=15,y=180)\n",
    "\n",
    "def clear_entry():\n",
    "    link.delete(0,END)\n",
    "    percent.delete(0,END)\n",
    "\n",
    "s = Button(root, text=\"Summarize\", command=lambda: summarizer(link.get(),percent.get()),padx=20)\n",
    "s.place(x=140,y=230)\n",
    "\n",
    "c = Button(root, text=\"Clear\", command=clear_entry,padx=15)\n",
    "c.place(x=270,y=230)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
